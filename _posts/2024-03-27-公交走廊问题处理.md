---
title: 公交走廊问题
date: 2024-03-27 19:53:00 +0800
categories: [tools, notes]
tags: [tools]     # TAG names should always be lowercase
math: true
mermaid: true
img_path: /commons/2024-03-27-公交走廊问题处理/
author: hupenghui
---

<!-- markdownlint-capture -->
<!-- markdownlint-disable -->
> 公交走廊就是根据公交的客运数据识别出路网中哪些路段是客流量比较大的，需要确保交通畅通，公共交通满足客运需求的。
{: .prompt-tip }
<!-- markdownlint-restore -->

## 交通数据处理

数据处理还有很长的路要走，向量化处理虽然快速，但是关键还是要学会按行处理。虽然按行处理比较慢，但是能让人想清楚处理的逻辑，直接向量化操作会很难想明白操作的逻辑。

交通数据分为两张表，一张表示所有的公共汽车站点，另一张表示公交线路经过的站点以及站点上的上客人数。
联想一个交通路网，很容易想到我们应该从上面的数据中提取出一个各个站点出发人数及出发方向的数据。在这里演示我们使用`pandas`的`dataframe`结构，因为向量化操作很方便。

```python
import pandas as pd
sheet1 = pd.read_excel('公交数据.xlsx',sheet_name='刷卡数据',header=0,engine='openpyxl') #读入公交线路及其经过的站点和刷卡数量信息
#线路编号   方向    站点编号    站点名称    日期    刷卡数量
sheet2 = pd.read_excel('公交数据.xlsx',sheet_name='站点数据',header=0,engine='openpyxl') #读入公交站点数据，构造站点名字到id的映射和id到名字的映射
#id line_identity   line_direction  station_number  station_identity    station_name    longitude   latitude
# 首先构造站点库，将上面的站点数据合并一下（不同公交线路可能会过同一个站点）
temp=sheet2.groupby('station_name').agg({'id':list}).reset_index()
#然后构造站点库
station_id={}
for i in range(len(temp)):
    station_id[temp[i:i+1]['station_name'].values[0]]=i
print("station to id done")
for key in station_id.keys():
    print(key,'->',station_id[key])
    break
id_station={}
for key,value in station_id.items():
    id_station[value]=key
print("id to station done")
for key in id_station.keys():
    print(key,'->',id_station[key])
    break
#由于数据不一致的问题，一些站点在公交线路中存在，但是在站点库中不存在，所以补充站点。
not_contain= sheet1[~ sheet1['站点名称'].isin(station_id.keys())]
not_contain_station = not_contain.groupby('站点名称').agg({'刷卡数量':list}).reset_index()
for i in range(len(not_contain_station)):
    id_station[len(station_id)]=not_contain_station[i:i+1]['站点名称'].values[0]
    station_id[not_contain_station[i:i+1]['站点名称'].values[0]]=len(station_id)
#把站点库保存下来
import json
data_json = json.dumps(station_id,ensure_ascii=False)
with open('station_to_id.json','w') as file:
    file.write(data_json)
print('write done')
data_json = json.dumps(id_station,ensure_ascii=False)
with open('id_to_station.json','w') as file:
    file.write(data_json)
print('write done')
#为了能够从直觉上清晰的感知到这个路网，我们不仅要知道公交站点在哪条线路上，更重要的是细粒度地明确站点之间的关系，然后才是站点在哪条线路上这种全局特征。
#换句话说，只知道公交站点在哪条线路上推不出来线路的链接顺序，但是从站点的链接顺序可以推出整条线路。所以站点链接顺序数据更加重要。
#由于线路数据站点的编号是不连续的（数据质量并不完美），所以我们没办法轻易的依靠id的先后顺序来join
#只能先把每条线路上的站点对应的id及刷卡数量记下来。方便后面按照id的大小先后做处理。
#统计一下线路-id-（站点，数量）的字典
line_seq_stat_nums={}
#线路编号   方向    站点编号    站点名称    日期    刷卡数量
for _ in range(len(sheet1)):
    line = sheet1[_:_+1]['线路编号'].values[0]
    sequence = sheet1[_:_+1]['站点编号'].values[0]
    station = sheet1[_:_+1]['站点名称'].values[0]
    nums = sheet1[_:_+1]['刷卡数量'].values[0]
    if line not in line_seq_stat_nums:
        temp={sequence:(station,nums)}
        line_seq_stat_nums[line]=temp
        continue
    if sequence not in line_seq_stat_nums[line]:
        line_seq_stat_nums[line][sequence]=(station,nums)
        continue
#形成一个新的dataframe，结构为：[此站，下站，线路，刷卡数]，站点链接数据
#可以使用join来构造，但是数据有问题，只能一行一行读取
this_next_line_nums=pd.DataFrame(columns=['此站','下站','线路','上车数量'])
for line in line_seq_stat_nums.keys():
    sequen = list(line_seq_stat_nums[line].keys())
    sequen.sort()
    for index in range(len(sequen)):
        ll = {'此站':line_seq_stat_nums[line][sequen[index]][0],'下站':line_seq_stat_nums[line][sequen[(index+1)%len(sequen)]][0],'线路':line,'上车数量':line_seq_stat_nums[line][sequen[index]][1]}
        ##print(ll)
        #this_next_line_nums.append(ll,ignore_index=True)
        this_next_line_nums.loc[len(this_next_line_nums)]=ll
station_out = this_next_line_nums.groupby('此站').agg({'下站':list,'上车数量':list,'线路':list}).reset_index()
#可以得到站点向路网中其他站点发送的客流量

```

新的可执行代码；

```python
import pandas as pd
sheet1 = pd.read_excel('公交数据.xlsx',sheet_name='刷卡数据',header=0,engine='openpyxl')
#线路编号	方向	站点编号	站点名称	日期	   刷卡数量
#1         1     1        火车站    2023-10-01  17
#print(sheet1.head())

sheet2 = pd.read_excel('公交数据.xlsx',sheet_name='站点数据',header=0,engine='openpyxl')
#	id	line_identity	line_direction	station_number	station_identity	station_name	longitude	latitude
#    1      1047               1              55                 1           碧海商业广场     106.618469  26.633052
#print(sheet2.head())
station_line=sheet1.groupby('站点名称').agg({'线路编号':list}).reset_index()
#站点名称       线路编号
#(招呼站)	  [226, 226, 228]
#station_line.head()
#print(len(station_line))#1138
#实际经过了1138个站点，其中还有三个是站点表里面没有的。站点表里有1449个站点，加上这三个不在的站点。一共有1452个站点，
station_line['lines'] = station_line.apply(lambda x : len(x['线路编号']),axis=1)
#站点名称         线路编号           lines
#(招呼站)	  [226, 226, 228]          3
#print(sum(station_line['lines']))#6480
#处理已知站点，不用地理位置信息，只根据流入流出确定
temp_station=sheet2.groupby('station_name').agg({'id':list}).reset_index()
# station_name                           id
#  (招呼站)             [7304, 7308, 7317, 7321, 10728, 10760]
#print(temp_station.head())
#把已知的站点信息统计一下
station_id={}
#station_name : id 
#(招呼站)     -> 0
for i in range(len(temp_station)):
    station_id[temp_station[i:i+1]['station_name'].values[0]]=i

print("station to id done")
#for key in station_id.keys():
#    print(key,'->',station_id[key])
#    break
id_station={}
#id -> station
#0 -> (招呼站)
for key,value in station_id.items():
    id_station[value]=key
print("id to station done")
#for key in id_station.keys():
#    print(key,'->',id_station[key])
#    break

#输出已知站点总数
#print(len(temp_station))#1449

line_station=sheet1.groupby('线路编号').agg({'站点名称':list}).reset_index()
#线路编号                        站点名称
#1         [火车站, 展览馆, 新路口, 邮电大楼, 大十字, 喷水池, 云中广场, 六广门, 北京路...
#print(line_station.head())
line_station['sites']=line_station.apply(lambda x:len(x['站点名称']),axis=1)
#线路编号                               站点名称                                       站点量
#1          [火车站, 展览馆, 新路口, 邮电大楼, 大十字, 喷水池, 云中广场, 六广门, 北京路...     18
#print(line_station.head())
#print(len(line_station))#203
#给每条线路上的每个站点一个编号
#print(sum(temp_line['sites']))#6480
#补充站点列表不包含的站点编号
not_contain= sheet1[~ sheet1['站点名称'].isin(station_id.keys())]
not_contain_station = not_contain.groupby('站点名称').agg({'刷卡数量':list}).reset_index()
for i in range(len(not_contain_station)):
    id_station[len(station_id)]=not_contain_station[i:i+1]['站点名称'].values[0]
    station_id[not_contain_station[i:i+1]['站点名称'].values[0]]=len(station_id)
#print(len(id_station))#1452
#先按照此站下一站的关系聚个类
#统计一下线路-id-（站点，数量）的字典，构造为字典方便索引
#print(sheet1[sheet1['线路编号']==1])
#线路编号	方向	站点编号	站点名称	    日期	    刷卡数量
#1          1     1        火车站       2023-10-01    17
line_seq_stat_nums={}
for _ in range(len(sheet1)):
    line = sheet1[_:_+1]['线路编号'].values[0]
    sequence = sheet1[_:_+1]['站点编号'].values[0]
    station = sheet1[_:_+1]['站点名称'].values[0]
    nums = sheet1[_:_+1]['刷卡数量'].values[0]
    direction = sheet1[_:_+1]['方向'].values[0]
    if line not in line_seq_stat_nums:
        temp={sequence:(station,nums,direction)}
        line_seq_stat_nums[line]=temp
        continue
    if sequence not in line_seq_stat_nums[line]:
        line_seq_stat_nums[line][sequence]=(station,nums,direction)
        continue
#字典结构:{线路编号：{站点编号：(站点名称，刷卡数量，方向)}}
print("dict done")
#形成一个新的dataframe，结构为：[此站，下站，线路，刷卡数]
#可以使用join来构造，但是数据有问题，站点编号是不连续的，只能一行一行读取
this_next_line_nums=pd.DataFrame(columns=['此站','下站','线路','上车数量','此站编号','下站编号','单程终点'])
for line in line_seq_stat_nums.keys():
    sequen = list(line_seq_stat_nums[line].keys())
    sequen.sort()
    for index in range(len(sequen)):
        ll = {'此站':line_seq_stat_nums[line][sequen[index]][0],'下站':line_seq_stat_nums[line][sequen[(index+1)%len(sequen)]][0],'线路':line,'上车数量':line_seq_stat_nums[line][sequen[index]][1],'此站编号':sequen[index],'下站编号':sequen[(index+1)%len(sequen)],'单程终点':0 if line_seq_stat_nums[line][sequen[(index+1)%len(sequen)]][2]!=line_seq_stat_nums[line][sequen[index]][2] else 1}
        ##print(ll)
        #this_next_line_nums.append(ll,ignore_index=True)
        this_next_line_nums.loc[len(this_next_line_nums)]=ll
print("dataframe done")
#此站          下站    线路   上车数量  此站编号 下站编号 单程终点
#火车站       展览馆     1      17        1       2      1
#展览馆       新路口     1      318       2       3      1
#北京西路口  黔灵山公园   1      582       10      12      0
#print(this_next_line_nums[this_next_line_nums['线路']==1])
neighbor_matrix=[]
#[[start,end]]
#[[7495,2348]]
this_middle_nums={}
#{'start':{'end':nums}}
#{'火车站': {'火车站_1_1_2_展览馆': 17}}
for row_index in range(len(this_next_line_nums)):
    line = this_next_line_nums[row_index:row_index+1]
    this_station=line['此站'].values[0]
    next_station=line['下站'].values[0]
    virtual_station=line['此站'].values[0]+'_'+str(line['此站编号'].values[0])+'_'+str(line['线路'].values[0])+'_'+str(line['下站编号'].values[0])+'_'+line['下站'].values[0]
    #station_id={}
    #station_name : id 
    #(招呼站)     -> 0
    #id_station={}
    #id -> station
    #0 -> (招呼站)
    if virtual_station not in station_id:
        id_station[len(station_id)]=virtual_station
        station_id[virtual_station]=len(station_id)
    neighbor_matrix.append([station_id[this_station],station_id[virtual_station]])
    neighbor_matrix.append([station_id[virtual_station],station_id[next_station]])
    if this_station not in this_middle_nums:
        this_middle_nums[this_station]={virtual_station:line['上车数量'].values[0]}
    else:
        this_middle_nums[this_station][virtual_station]=line['上车数量'].values[0]
#这样子我们既有了邻接矩阵，也有了实际的上车数量
print(len(station_id))
import numpy as np
station_features=np.zeros((len(station_id),len(station_id)),dtype=float)
for i in range(len(station_id)):
    if id_station[i] in this_middle_nums:
        for middle in this_middle_nums[id_station[i]]:
            station_features[i,station_id[middle]]=float(this_middle_nums[id_station[i]][middle])#设置稀疏矩阵的第几行第几列为需要的值。
    else:
        continue
#定义损失函数
def loss(predict_matrix,true_matrix):
    #预测矩阵中每一行流出的量求和应该等于实际流量中流入的量
    row_sum = predict_matrix.sum(axis=0)
    temp = predict_matrix+true_matrix
    column_sum = temp.sum(axis=1)
    loss = sum((row_sum-column_sum)**2)
    return loss
```