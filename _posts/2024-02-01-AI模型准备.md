---
title: AI模型准备
date: 2024-02-01 16:09:00 +0800
categories: [tools, notes]
tags: [tools]     # TAG names should always be lowercase
math: true
mermaid: true
img_path: /commons/2024-02-01-AI模型准备/
author: hupenghui
---

## 前言

进行人工智能相关开发，在数据准备好以后我们就需要构建模型开始训练，这包含很多工作，包括：模型代码的实现，训练环境的搭建。

## 可迁移训练环境的构建

可迁移环境的实现有两种主要方式：[conda](https://docs.conda.io/projects/miniconda/en/latest/)和[docker](https://docs.docker.com/engine/install/ubuntu/)。第一种是使用conda新建一个python环境。优点是简单易用，缺点是只能在本机器上用，如果需要在其他平台上运行就会很麻烦。第二种是使用docker构建一个包含底层环境的容器，优点是docker安装在哪里，代码就能在哪里运行，缺点是占用空间稍微大一点，构建容器用的时间也稍微长一些。

### conda环境

使用conda构建python环境的代码如下所示（以下代码都是针对linux-x86平台）：

```python
#安装miniconda
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
~/miniconda3/bin/conda init zsh
#此时重新打开命令行窗口就可以看conda的默认base环境
#配置conda为国内的阿里云源
vim ~/.condarc
#在命令行中键入英文i，切换为插入模式，输入以下内容
channels:
  - defaults
show_channel_urls: true
default_channels:
  - http://mirrors.aliyun.com/anaconda/pkgs/main
  - http://mirrors.aliyun.com/anaconda/pkgs/r
  - http://mirrors.aliyun.com/anaconda/pkgs/msys2
custom_channels:
  conda-forge: http://mirrors.aliyun.com/anaconda/cloud
  msys2: http://mirrors.aliyun.com/anaconda/cloud
  bioconda: http://mirrors.aliyun.com/anaconda/cloud
  menpo: http://mirrors.aliyun.com/anaconda/cloud
  pytorch: http://mirrors.aliyun.com/anaconda/cloud
  simpleitk: http://mirrors.aliyun.com/anaconda/cloud
#然后键盘按下esc键，推出插入模式，再按下英文输入法下的:wq即可退出
#配置pip为国内的阿里云源
vim ~/.pip/pip.conf
#键盘按下英文输入法的i，切换为插入模式，复制粘贴以下内容
[global]
index-url = http://mirrors.aliyun.com/pypi/simple/
[install]conda 
trusted-host=mirrors.aliyun.com
#然后键盘按下esc键，推出插入模式，再按下英文输入法下的:wq即可退出
#更新conda环境使得阿里云源生效
conda update --all
#新建python环境
conda create -n env_name python=version
pip install -r requirements.txt
```

### docker环境

使用docker构建镜像的命令如下所示（本部分介绍的是以别人的镜像为基础添加组件来新建镜像的）：

```python
#基镜像
FROM registryonline-hulk.sankuai.com/custom_prod/com.sankuai.data.hadoop.gpu/data-pt2.0.1-py39-nccl2.14-cuda11.7-flashatten1.0.4-c20e7d9f
#复制文件
COPY id_rsa.pub /root/.ssh/
COPY id_rsa /root/.ssh/
#赋予执行权限
RUN chmod 600 /root/.ssh/id_rsa && mkdir -p /sources
#通过pip安装包
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  langchain==0.0.24
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  numpy==1.19.5
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  pyserini==0.19.0
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  torch_geometric
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  tqdm
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  transformers
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  sentence_transformers
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  datasets
RUN pip3 install --no-cache-dir -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com  faiss-gpu
#构建环境变量
ENV PYTHONPATH="~:$PYTHONPATH"
#清理不必要的文件
RUN rm -v /root/.ssh/id_rsa* && rm -rf /sources && rm -rf /root/.cache
```

## 模型构建

在配置好环境以后就要开始编写模型，大型模型一般不是一天写好的，可能需要持久作战，所以不论是日志还是类型注释都很重要。另外代码的运行一般都是通过命令行加上关键字参数的形式，所以还需要对命令参数进行处理的库。有些参数可以用数据类`dataclass`来定义，比如各个函数都可能用到的。训练数据读取使用`pandas`，数值化使用`numpy`，当训练数据比较大不能读入内存中还可以使用`numpy`的`memmap`函数来实现。
参考代码：[PyToch手写识别GPU训练任务实例](https://openi.pcl.ac.cn/docs/index.html#/quickstart/quickstartGPU)

```python
#!/usr/bin/python
#指定解释器行
# -*- coding:utf-8 -*-
#指定编码语言行

import logging #引入日志库
import argparse #引入命令行解析库
import os #引入操作系统库
import sys #引入python解释器库
from typing import List,Tuple,Dict,Set,Union,Optional #引入类型注释库
from dataclasses import dataclass, field #引入数据类
import torch
import torch.nn as nn

#定义一个argparse对象记录命令行参数
parse=argparse.ArgumentParser(description='Pytorch Example')
parse.add_argument('--epoch_size',type=int,default=10,help='how much epoch to train')
parse.add_argument('--batch_size',type=int,default=256,help='how much batch_size in epoch')#添加参数
arg,unknown = parse.parse_known_args()#执行程序时会从命令行中解析命令行参数
#也可以打包为一个函数
def parse_arg():
  parse=argparse.ArgumentParser(description='Pytorch Example')
  parse.add_argument('--epoch_size',type=int,default=10,help='how much epoch to train')
  parse.add_argument('--batch_size',type=int,default=256,help='how much batch_size in epoch')
  arg,unknown=parse.parse_known_args()
  return arg, unknown
arg , unknown = parse_arg()
#定义一个数据类
@dataclass
class config:
  workers: int=field(default=0,metadata={'description':'this is global workers config'})
exp_config = config()
workers = exp_config.workers
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = Model().to(device)
optimizer = SGD(model.parameters(), lr=1e-1)
cost = CrossEntropyLoss()
#定义一个日志对象，设置日志规则

## 定义一个模型
class mlp(nn.Module):
  def __init__(self,input_size,output_size):
    self.input=input_size
    self.output=output_size
    self.net=torch.nn.Linear(self.input,self.output)
  def forward(self,x):
    return self.net(x)

## 训练模型
def train(model,train_loader,epoch):
  model.train()
  train_loss=0
  for i,data in enumerate(train_loader,0):
    x,y = data
    x = x.to(device)
    y = y.to(device)
    optimizer.zero_grad()
    y_hat = model(x)
    loss = (y-y_hat)**2
    loss.backward()
    optimizer.step()
    train_loss += loss
  loss_mean = train_loss/(i+1)
  print('epoch:{} \t loss:{}'.format(epoch,loss_mean.item()))

# 模型测试
def test(model, test_loader, test_data):
  model.eval()
  test_loss = 0
  correct = 0
  with torch.no_grad():
    for i, data in enumerate(test_loader, 0):
      x, y = data
      x = x.to(device)
      y = y.to(device)
      optimizer.zero_grad()
      y_hat = model(x)
      test_loss += (y_hat-y)**2
      pred = y_hat.max(1, keepdim=True)[1]
      correct += pred.eq(y.view_as(pred)).sum().item()
  test_loss /= (i+1)
  print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(test_loss, correct, len(test_data), 100. * correct / len(test_data)))

if __name__=='__main__':
  args,unknown = parse_arg()
  net=mlp(3,5)
  model = nn.dataparallel(net)
  


```
