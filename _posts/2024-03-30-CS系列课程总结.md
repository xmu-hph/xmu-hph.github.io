---
title: CS系列课程总结
date: 2024-03-30 16:01:00 +0800
categories: [tools, notes]
tags: [tools]     # TAG names should always be lowercase
math: true
mermaid: true
img_path: /commons/2024-03-30-CS系列课程总结/
author: hupenghui
---

<!-- markdownlint-capture -->
<!-- markdownlint-disable -->
> 学习的理论与计算机中实际运行的代码之间总是感觉有间隙，大部分介绍文档都是模棱两可，他们也知道有区别，但是就是不敢说或者说他们也不知道怎么描述这个问题。`CS`系列课程就很好，很清晰，不同的概念就是会明确表示这是不同的概念，不会因为概念上的多义而让你模棱两可。比如线性代数理论，书中学习的是线性代数理论，但是计算机中实现的张量代数理论，这两者是不同的，`CS`就非常明确的说这是不同的。
{: .prompt-tip }
<!-- markdownlint-restore -->

## 强化学习基础

1. [Deep Reinforcement Learning](https://rail.eecs.berkeley.edu/deeprlcourse/)
    - 提出张量代数这个名词，解决了线性代数应用于高维张量上的困境。
    - 策略梯度的分解公式分为了两步，第一步先确定对单个奖励还是单个概率分布进行求和，第二步才是对求和后的结果进行求偏导，才能正确对策略梯度进行分解。从奖励的分解角度看，很容易得到策略梯度的表达式为：\$$ \partial_{\Theta}\sum_{s}\sum_{a}P(s)\pi(a|s)r(s,a)=\sum_{s}\sum_{a}\partial_{\Theta}[P(s)\pi(a|s)]r(s,a) $$，如果从概率的分解角度来看。
