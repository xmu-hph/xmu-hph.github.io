---
title: CS系列课程总结
date: 2024-03-30 16:01:00 +0800
categories: [tools, notes]
tags: [tools]     # TAG names should always be lowercase
math: true
mermaid: true
img_path: /commons/2024-03-30-CS系列课程总结/
author: hupenghui
---

<!-- markdownlint-capture -->
<!-- markdownlint-disable -->
> 学习的理论与计算机中实际运行的代码之间总是感觉有间隙，大部分介绍文档都是模棱两可，他们也知道有区别，但是就是不敢说或者说他们也不知道怎么描述这个问题。`CS`系列课程就很好，很清晰，不同的概念就是会明确表示这是不同的概念，不会因为概念上的多义而让你模棱两可。比如线性代数理论，书中学习的是线性代数理论，但是计算机中实现的张量代数理论，这两者是不同的，`CS`就非常明确的说这是不同的。
{: .prompt-tip }
<!-- markdownlint-restore -->

## 强化学习基础

$$
\begin{equation}
  \nabla_{\theta}\sum_{s}\sum_{a}P(s)\pi(a|s)r(s,a)=\sum_{s}\sum_{a}\nabla_{\theta}[P(s)\pi(a|s)]r(s,a)
  \label{eq:series}
\end{equation}
$$

\eqref{eq:series} 对于回报均值的计算采用了将回报分解为奖励的方式 $r(\tau)=\sum_{i} r(s_i,a_i)$:

$$
\begin{equation}
  {R}=\sum_{s_1}\sum_{a_1}p(s_1)\pi(a_1|s_1)r(s_1,a_1)+\sum_{s_1}\sum_{a_1}\sum_{s_2}\sum_{a_2}p(s_1)\pi(a_1|s_1)p(s_2|s_1,a_1)\pi(a_2|s_2)r(s_2,a_2)+\cdots
  \label{eq:mean_return}
\end{equation}
$$

The mean of the return will be \eqref{eq:mean_return}:

$$
\begin{equation}
  {R}=\sum_{s_1}\sum_{a_1}p(s_1)\frac{\pi(a_1|s_1)}{\pi_o(a_1|s_1)}\pi_o(a_1|s_1)r(s_1,a_1)+\sum_{s_1}\sum_{a_1}\sum_{s_2}\sum_{a_2}p(s_1)\pi(a_1|s_1)p(s_2|s_1,a_1)\pi(a_2|s_2)\frac{\pi_o(a_1|s_1)\pi_o(a_2|s_2)}{\pi_o(a_1|s_1)\pi_o(a_2|s_2)}r(s_2,a_2)+\cdots
  \label{eq:importance_sample}
\end{equation}
$$

if we use importance sample, then the mean of the return will be \eqref{eq:importance_sample}:

$$
\begin{equation}
  {R}=\sum_{s_1}\sum_{a_1}p(s_1)\pi_o(a_1|s_1)\frac{\pi(a_1|s_1)}{\pi_o(a_1|s_1)}r(s_1,a_1)+\sum_{s_1}\sum_{a_1}\sum_{s_2}\sum_{a_2}p(s_1)\pi_o(a_1|s_1)p(s_2|s_1,a_1)\pi_o(a_2|s_2)\frac{\pi(a_1|s_1)\pi(a_2|s_2)}{\pi_o(a_1|s_1)\pi_o(a_2|s_2)}r(s_2,a_2)+\cdots
  \label{eq:factor_resequence}
\end{equation}
$$

We can change the sequence of the factor in above equation \eqref{eq:factor_resequence}.
